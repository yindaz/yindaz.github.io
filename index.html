
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Yinda Zhang">
    <meta name="author" content="Yinda Zhang">
    <meta name="keywords" content="Yinda Zhang">

    <link rel="shortcut icon" href="./img/favicon.ico">

    <title>Yinda Zhang | Google</title>

    <!-- Bootstrap core CSS -->
    <!-- <link href="css/bootstrap.min.css" rel="stylesheet"> -->
    <!-- <link href="css/bootstrap-theme.min.css" rel="stylesheet"> -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap-theme.min.css">
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>

    <!-- Custom styles for this template -->
    <link href="css/starter-template.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <link href="css/theme.css" rel="stylesheet">

    <!-- Just for debugging purposes. Don't actually copy this line! -->
    <!--[if lt IE 9]><script src="../../assets/js/ie8-responsive-file-warning.js"></script><![endif]-->

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>

  <body>

    

    <div class="navbar navbar-inverse navbar-fixed-top" role="navigation" id="navbar">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="index.html">Yinda Zhang</a>
        </div>
        <div class="collapse navbar-collapse">
          <ul class="nav navbar-nav">
            <li><a href="#">Home</a></li>
            <li><a href="#news">News</a></li>
            <!-- <li><a href="#recent">Recent Work</a></li> -->
            <li><a href="#publication">Publications</a></li>
            <li><a href="#experience">Experiences</a></li>
            <li><a href="#service">Services</a></li>
            <!-- <li><a href="#talk">Talks</a></li> -->
            <li><a href="#contact">Contacts</a></li>
            <li><a href=https://goo.gl/forms/cv4UmvNwrA4K6VOi2></a></li>
          </ul>
        </div><!--/.nav-collapse -->
      </div>
    </div>


<!--     <div class="jumbotron header-img" id="header">
      <div class="container" style="color:white">
      </div>
    </div> -->

    <div class="container theme-showcase maintext">
        <div class="starter-template">
            <div class="row">
                <!-- <div class="col-md-1">  </div> -->
                <div class="col-md-4">
                    <!-- <br> -->
                    <img src="./img/portrait-2.png" class="img-thumbnail" alt="My  Portrait.">
                </div>
                <div class="col-md-2">  </div>
                <div class="col-md-8">
                    <h1>Yinda Zhang</h1>
                    <br>
                    <!-- <h4>Brief Bio.:</h4> -->

                    <p>I am a Senior Research Scientist at Google. 

                    My research interests lie at the intersection of computer vision, computer graphics, and machine learning. Recently, I focus on empowering 3D vision and perception via machine learning, including dense depth estimation, 3D shape analysis, 3D scene understanding, and neural rendering.

                    I received my Ph.D. in Computer Science from <a href="http://www.princeton.edu/">Princeton University</a>, advised by <a href="http://www.cs.princeton.edu/~funk/">Professor Thomas Funkhouser</a>. Before that, I received a Bachelor degree from Dept. Automation in <a href="http://www.tsinghua.edu.cn/publish/thu2018/index.html">Tsinghua University</a>, and a Master degree from Dept. ECE in <a href="http://nus.edu.sg/">National University of Singapore</a> co-supervised by <a href="https://www.cs.sfu.ca/~pingtan/">Prof. Ping Tan</a> and <a href="https://www.ece.nus.edu.sg/stfpage/eleyans/">Prof. Shuicheng Yan</a>. 
                    <!-- My research mainly focus on machine learning, computer vision, and computer graphics. Recently, I am working on 3D scene understanding, where the goal is to measure 3D geometry and semantics of the surrounding environment leveraging deep learning technology. -->
                    </p>
                    <br>

                    <table>
                    <!-- <tr><td>Email:</td><td><span class="estr">yindaz (at) gmail (dot) com</span></td></tr> -->
                    <tr><td>Email:</td><td>yinda<span class="hiddenemail">nospam</span>z (at) gmail (dot) com</td></tr>
<!--                     <tr><td>&nbsp;</td><td></td></tr>
                    <tr><td>About me:</td><td><a href="yinda_cv.pdf">Resume</a></td></tr> -->
                    <tr><td>&nbsp;</td><td></td></tr>
                    <tr><td>Find me on:&nbsp;&nbsp;</td><td>
                      <ul class="social">
                        <li class="googlescholar"><a href="https://scholar.google.com/citations?user=F15ODMIAAAAJ&hl=en&oi=ao">Google Scholar</a></li>
                        <li class="github"><a href="https://github.com/yindaz">GitHub</a></li>
                        <li class="linkedin"><a href="https://www.linkedin.com/in/yinda-zhang-9aa23632/">LinkedIn</a></li>
                        <!-- <li class="facebook"><a href="http://www.facebook.com/">Facebook</a></li> -->
                      </ul>
                    </td></tr>
                    </table>

                </div>

            </div>
        </div>

        <center><font color="white" size="32"><b>YES! YES! YES! YES! YES&uarr; YES! YES! YES!</b></font></center>

        <div id="news"></div>
        <br>
        <div class="page-header">
            <h2>News</h2>
        </div>

        <div class="news_table">
            <table>
            	<tr>
                  <td class="news_date">2021.12</td>
                  <td class="news_news">I am thrilled to announce the arrival of <a href="img/JinxianZhang.jpeg">a wonderful baby boy</a> to our home.
                  </td>
                </tr>
                <tr>
                  <td class="news_date">2021.11</td>
                  <td class="news_news">One paper got accepted by AAAI2022.
                  </td>
                </tr>
            	<tr>
                  <td class="news_date">2021.07</td>
                  <td class="news_news"><a href="#ICCV2021_DeepPanoContext">Five</a> papers are accepted by ICCV2021.
                  </td>
                </tr>
                <tr>
                  <td class="news_date">2021.03</td>
                  <td class="news_news"><a href="#CVPR2021_HumanGPS">Five</a> papers (2 Orals + 3 Posters) are accepted by CVPR2021.
                  </td>
                </tr>
                <tr>
                  <td class="news_date">2020.07</td>
                  <td class="news_news"><a href="#publication_dudunet">Three</a> papers (2 Orals + 1 Posters) are accepted by ECCV2020.
                  </td>
                </tr>
                <tr>
                  <td class="news_date">2020.04</td>
                  <td class="news_news">Our deep learning <b>depth refinement</b> solution is checked in Pixel4 front-facing camera to support computational photography and AR applications. Learn more here: <a href="https://ai.googleblog.com/2020/04/udepth-real-time-3d-depth-sensing-on.html">Google AI blogpost</a>.
                  </td>
                </tr>
                <tr>
                  <td class="news_date">2020.02</td>
                  <td class="news_news"><a href="#publication_pixel2mesh">Pixel2Mesh</a>  is accepted by IEEE Transactions of Pattern Analysis and Machine Intelligence.</td>
                </tr>
                <tr>
                <tr>
                  <td class="news_date">2020.02</td>
                  <td class="news_news"><a href="#publication_NPT">Four</a> papers are accepted by CVPR2020.</td>
                </tr>
                <tr>
                  <td class="news_date">2019.12</td>
                  <td class="news_news">Our deep learning based solution for image based depth estimation has been deloyed on Google Pixel4 for Portrait Mode. Check this <a href="https://ai.googleblog.com/2019/12/improvements-to-portrait-mode-on-google.html">Google AI blogpost</a> for more details.</td>
                </tr>
                <tr>
                  <td class="news_date">2019.07</td>
                  <td class="news_news">Pixel2Mesh++ is accepted by ICCV2019. Check <a href="https://arxiv.org/abs/1908.01491">here</a> for the paper.</td>
                </tr>
                <tr>
                  <td class="news_date">2019.03</td>
                  <td class="news_news">DeepLidar paper is accepted by CVPR2019.</td>
                </tr>
                <tr>
                  <td class="news_date">2018.12</td>
                  <td class="news_news">I started working at Google as a Research Scientist.</td>
                </tr>
                <tr>
                  <td class="news_date">2018.11</td>
                  <td class="news_news">I obtain Ph.D degree from Princeton University.</td>
                </tr>
                <tr>
                  <td class="news_date">2018.11</td>
                  <td class="news_news">I am awarded as <a href="http://www.siebelscholars.com/">Siebel Scholar Class of 2019</a>.</td>
                </tr>
                <tr>
                  <td class="news_date">2018.07</td>
                  <td class="news_news">ActiveStereoNet is accepted as oral presentation by <a href="https://eccv2018.org/">ECCV 2018</a>.</td>
                </tr>
                <tr>
                  <td class="news_date">2018.07</td>
                  <td class="news_news">Pixel2Mesh is accepted by <a href="https://eccv2018.org/">ECCV 2018</a>.</td>
                </tr>
            </table>
        </div>      

        <!-- <ul>
            <li>Check our <a href="https://arxiv.org/abs/1911.13225">solution</a> to render deep implicit function.</li>
            <li>Pixel2Mesh++ is accepted by ICCV2019. Check <a href="https://arxiv.org/abs/1908.01491">here</a> for the paper.</li>
            <li>DeepLidar paper is accepted by CVPR2019.</li>
            <li>I jointhandned Google in Dec 2018.</li>
            <li>I am awarded as <a href="http://www.siebelscholars.com/">Siebel Scholar Class of 2019</a>.</li>
            <li>ActiveStereoNet is accepted as oral presentation by <a href="https://eccv2018.org/">ECCV 2018</a>.</li>
            <li>Pixel2Mesh is accepted by <a href="https://eccv2018.org/">ECCV 2018</a>.</li>
        </ul> -->


        <!-- <div class="page-header" id="recent">
            <h1>Recent Work</h1>
        </div> -->



        <div id="publication"></div>

	<br>
        
        <div class="page-header">
            <h2>Publications</h2>
        </div>
        
        <div class="row featurette align-items-center" id="AAAI2022_handpose">
            <div class="col-md-2">

                <img class="featurette-image img-responsive img-thumbnail"  src="publication/AAAI2022/view-selection-hand.jpg" alt="view-selection-hand" style="width:256px;" />
            </div>
            <div class="col-md-10">
                <h4 class="featurette-heading" data-toggle="tooltip" > Efficient Virtual View Selection for 3D Hand Pose Estimation</h4>
                <p> J. Cheng, Y. Wan, D. Zuo, C. Ma, J. Gu, P. Tan, H. Wang, X. Deng, <b>Y. Zhang</b></p>
                <p> AAAI Conference on Artificial Intelligence (AAAI2022)</p>
                <p> 
                [<a href="">Paper (Coming Soon)</a>]
                [<a href="">Project Webpage (Coming Soon)</a>]
                [<a href="">Codes (Coming Soon)</a>]
                </p>
            </div>
        </div>

        <br>
        
        <div class="row featurette align-items-center" id="ICCV2021_DeepPanoContext">
            <div class="col-md-2">

                <img class="featurette-image img-responsive img-thumbnail"  src="publication/iccv2021/deeppanocontext.jpg" alt="deeppanocontext" style="width:256px;" />
            </div>
            <div class="col-md-10">
                <h4 class="featurette-heading" data-toggle="tooltip" > DeepPanoContext: Panoramic 3D Scene Understanding with Holistic Scene Context Graph and Relation-based Optimization</h4>
                <p> C. Zhang, Z. Cui, C. Chen, S. Liu, B. Zeng, H. Bao, <b>Y. Zhang</b></p>
                <p> International Conference on Computer Vision (ICCV 2021), Oral Presentation</p>
                <p> 
                [<a href="https://arxiv.org/abs/2108.10743">Paper</a>]
                [<a href="https://chengzhag.github.io/publication/dpc/">Project Webpage</a>]
                [<a href="https://github.com/chengzhag/DeepPanoContext">Codes</a>]
                </p>
            </div>
        </div>

        <br>
        
        <div class="row featurette align-items-center" id="ICCV2021_ObjectNeRF">
            <div class="col-md-2">

                <img class="featurette-image img-responsive img-thumbnail"  src="publication/iccv2021/object_nerf.jpg" alt="object_nerf" style="width:256px;" />
            </div>
            <div class="col-md-10">
                <h4 class="featurette-heading" data-toggle="tooltip" > Learning Object-Compositional Neural Radiance Field
for Editable Scene Rendering</h4>
                <p> B. Yang, <b>Y. Zhang</b>, Y. Xu, Y. Li, H. Zhou, H. Bao, G. Zhang, Z. Cui
 </p>
                <p> International Conference on Computer Vision (ICCV 2021)</p>
                <p> 
                [<a href="https://arxiv.org/abs/2109.01847">Paper</a>]
                [<a href="https://zju3dv.github.io/object_nerf/">Project Webpage</a>]
                [<a href="https://github.com/zju3dv/object_nerf">Codes</a>]
                </p>
            </div>
        </div>

        <br>
        
        <div class="row featurette align-items-center" id="ICCV2021_MDIF">
            <div class="col-md-2">

                <img class="featurette-image img-responsive img-thumbnail"  src="publication/iccv2021/mdif.jpg" alt="mdif" style="width:256px;" />
            </div>
            <div class="col-md-10">
                <h4 class="featurette-heading" data-toggle="tooltip" > Multiresolution Deep Implicit Functions for 3D Shape Representation</h4>
                <p> Z. Chen, <b>Y. Zhang</b>, K. Genova, S. Fanello, S. Bouaziz, C. Haene, R. Du, C. Keskin, T. Funkhouser, D. Tang</p>
                <p> International Conference on Computer Vision (ICCV 2021)</p>
                <p> 
                [<a href="https://arxiv.org/abs/2109.05591">Paper</a>]
                [<a href="https://github.com/dhtang/mdif">Codes</a>]
                </p>
            </div>
        </div>

        <br>
        
        <div class="row featurette align-items-center" id="ICCV2021_DeepHybridPrior">
            <div class="col-md-2">

                <img class="featurette-image img-responsive img-thumbnail"  src="publication/iccv2021/deephybridprior.jpg" alt="deephybridprior" style="width:256px;" />
            </div>
            <div class="col-md-10">
                <h4 class="featurette-heading" data-toggle="tooltip" > Deep Hybrid Self-Prior for Full 3D Mesh Generation</h4>
                <p> X. Wei, Z. Chen, Y. Fu, Z. Cui, <b>Y. Zhang</b></p>
                <p> International Conference on Computer Vision (ICCV 2021)</p>
                <p> 
                [<a href="https://arxiv.org/abs/2108.08017">Paper</a>]
                [<a href="https://yqdch.github.io/DHSP3D/">Project Webpage</a>]
                [<a href="https://github.com/weixk2015/DHSP3D">Codes</a>]
                </p>
            </div>
        </div>

        <br>
        
        <div class="row featurette align-items-center" id="ICCV2021_InterHand">
            <div class="col-md-2">

                <img class="featurette-image img-responsive img-thumbnail"  src="publication/iccv2021/interhand.jpg" alt="interhand" style="width:256px;" />
            </div>
            <div class="col-md-10">
                <h4 class="featurette-heading" data-toggle="tooltip" > Interacting Two-Hand 3D Pose and Shape Reconstruction
from Single Color Image</h4>
                <p> B. Zhang, Y. Wang, X. Deng, <b>Y. Zhang</b>, P. Tan, C. Ma, H. Wang</p>
                <p> International Conference on Computer Vision (ICCV 2021)</p>
                <p> 
                [<a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Zhang_Interacting_Two-Hand_3D_Pose_and_Shape_Reconstruction_From_Single_Color_ICCV_2021_paper.pdf">Paper</a>]
                [<a href="https://baowenz.github.io/Intershape/">Project Webpage</a>]
                [<a href="https://github.com/BaowenZ/Two-Hand-Shape-Pose">Codes</a>]
                </p>
            </div>
        </div>

        <br>
        
        <div class="row featurette align-items-center" id="CVPR2021_HumanGPS">
            <div class="col-md-2">

                <img class="featurette-image img-responsive img-thumbnail"  src="publication/cvpr2021/humangps.jpg" alt="humangps" style="width:256px;" />
            </div>
            <div class="col-md-10">
                <h4 class="featurette-heading" data-toggle="tooltip" > HumanGPS: Geodesic PreServing Feature for Dense Human Correspondences</h4>
                <p> F. Tan, D. Tang, M. Dou, K. Guo, R. Pandey, C. Keskin, R. Du, D. Sun, S. Bouaziz, S. Fanello, P. Tan, <b>Y. Zhang</b></p>
                <p> Computer Vision and Pattern Recognition (CVPR 2021)</p>
                <p> 
                [<a href="https://arxiv.org/abs/2103.15573">Paper</a>]
                [<a href="https://feitongt.github.io/HumanGPS/">Project Webpage</a>]
                [<a href="https://github.com/googleinterns/humangps">Codes</a>]
                </p>
            </div>
        </div>

        <br>
        
        <div class="row featurette align-items-center">
            <div class="col-md-2">
            
                <img class="featurette-image img-responsive img-thumbnail"  src="publication/cvpr2021/implicit_scene.jpg" alt="implicit_scene" style="width:256px;" />
            </div>
            <div class="col-md-10">
                <h4 class="featurette-heading" data-toggle="tooltip" > Holistic 3D Scene Understanding from a Single Image with Implicit Representation</h4>
                <p> C. Zhang<sup>*</sup>, Z. Cui<sup>*</sup>, <b>Y. Zhang<sup>*</sup></b>, B. Zeng, M. Pollefeys, S. Liu</p>
                <p> Computer Vision and Pattern Recognition (CVPR 2021)</p>
                <p> 
                [<a href="https://arxiv.org/abs/2103.06422">Paper</a>]
                [<a href="https://chengzhag.github.io/publication/im3d/">Project Webpage</a>]
                [<a href="https://github.com/chengzhag/Implicit3DUnderstanding">Codes</a>]
                </p>
            </div>
        </div>

        <br>
        
        <div class="row featurette align-items-center">
            <div class="col-md-2">
                <br>
                <img class="featurette-image img-responsive img-thumbnail"  src="publication/cvpr2021/4d_human_representation.jpg" alt="4d_human_representation" style="width:256px;" />
            </div>
            <div class="col-md-10">
                <h4 class="featurette-heading" data-toggle="tooltip" > Learning Compositional Representation for 4D Captures with Neural ODE</h4>
                <p> B. Jiang<sup>*</sup>, <b>Y. Zhang<sup>*</sup></b>, X. Wei, X. Xue, Y. Fu.</p>
                <p> Computer Vision and Pattern Recognition (CVPR 2021)</p>
                <p> 
                [<a href="https://arxiv.org/abs/2103.08271">Paper</a>]
                [<a href="https://boyanjiang.github.io/4D-CR/">Project Webpage</a>]
                [<a href="https://github.com/BoyanJIANG/4D-Compositional-Representation">Data, Model, Code</a>]
                [<a href="https://youtu.be/F-zYAPyAmWE">Video</a>]
                </p>
            </div>
        </div>

        <br>
        
        <div class="row featurette align-items-center">
            <div class="col-md-2">
                <br>
                <img class="featurette-image img-responsive img-thumbnail"  src="publication/cvpr2021/spatial_outdoor_lighting.jpg" alt="spatial_outdoor_lighting" style="width:256px;" />
            </div>
            <div class="col-md-10">
                <h4 class="featurette-heading" data-toggle="tooltip" > Spatially-Varying Outdoor Lighting Estimation from Intrinsics</h4>
                <p> Y. Zhu, <b>Y. Zhang</b>, S. Li, B. Shi</p>
                <p> Computer Vision and Pattern Recognition (CVPR 2021), Oral Presentation</p>
                <p> 
                [<a href="https://arxiv.org/abs/2104.04160">Paper</a>]
                </p>
            </div>
        </div>

        <br>
        
        <div class="row featurette align-items-center">
            <div class="col-md-2">
                <br>
                <img class="featurette-image img-responsive img-thumbnail"  src="publication/cvpr2021/hitnet.jpg" alt="hitnet" style="width:256px;" />
            </div>
            <div class="col-md-10">
                <h4 class="featurette-heading" data-toggle="tooltip" > HITNet: Hierarchical Iterative Tile Refinement Network for Real-time Stereo Matching</h4>
                <p> V. Tankovich, C. Hane, <b>Y. Zhang</b>, A. Kowdle, S. Fanello, S. Bouaziz</p>
                <p> Computer Vision and Pattern Recognition (CVPR 2021), Oral Presentation</p>
                <p> 
                [<a href="https://arxiv.org/abs/2007.12140">Paper</a>]
                [<a href="https://github.com/google-research/google-research/tree/master/hitnet">Pretrained Model and Evaluation Code</a>]
                </p>
            </div>
        </div>

        <br>
        
        <div class="row featurette align-items-center" id="publication_dudunet">
            <div class="col-md-2">
                <br>
                <img class="featurette-image img-responsive img-thumbnail"  src="publication/du2net/dudunet.jpg" alt="dudunet" style="width:256px;" />
            </div>
            <div class="col-md-10">
                <h4 class="featurette-heading" data-toggle="tooltip" > Du2Net: Learning Depth Estimation from Dual-Cameras and Dual-Pixels</h4>
                <p> <b>Y. Zhang</b>, N. Wadhwa, S. Orts-Escolano, C. haene, S. Fanello, R. Garg</p>
                <p> European Conference on Computer Vision (ECCV 2020), Oral Presentation</p>
                <p> 
                [<a href="https://arxiv.org/abs/2003.14299">Paper</a>]
                [<a href="https://augmentedperception.github.io/du2net/">Project Webpage</a>]
                </p>
            </div>
        </div>

        <br>
        
        <div class="row featurette align-items-center">
            <div class="col-md-2">
                <br>
                <img class="featurette-image img-responsive img-thumbnail"  src="publication/deepsfm/deepsfm.jpg" alt="deepsfm" style="width:256px;" />
            </div>
            <div class="col-md-10">
                <h4 class="featurette-heading" data-toggle="tooltip" > DeepSFM: Structure From Motion Via Deep Bundle Adjustment</h4>
                <p> X. Wei<sup>*</sup>, <b>Y. Zhang<sup>*</sup></b>, Z. Li<sup>*</sup>, Y. Fu, X. Xue</p>
                <p> European Conference on Computer Vision (ECCV 2020), Oral Presentation</p>
                <p> 
                [<a href="https://arxiv.org/abs/1912.09697">Paper</a>]
                [<a href="https://weixk2015.github.io/DeepSFM/">Project Webpage</a>]
                [<a href="https://github.com/weixk2015/DeepSFM">Codes</a>]
                </p>
            </div>
        </div>

        <br>
        
        <div class="row featurette align-items-center">
            <div class="col-md-2">
                <br>
                <img class="featurette-image img-responsive img-thumbnail"  src="publication/geolayout/geolayout.jpg" alt="geolayout" style="width:256px;" />
            </div>
            <div class="col-md-10">
                <h4 class="featurette-heading" data-toggle="tooltip" > 	GeoLayout: Geometry Driven Room Layout Estimation Based on Depth Maps of Planes</h4>
                <p> W. Zhang, W. Zhang, <b>Y. Zhang</b></p>
                <p> European Conference on Computer Vision (ECCV 2020)</p>
                <p> 
                [<a href="https://arxiv.org/abs/2008.06286">Paper</a>]
                [<a href="https://ayasechihaya.github.io/">Project Webpage</a>]
                [<a href="https://vsislab.github.io/Matterport3D-Layout/">Matterport3D-Layout Dataset</a>]
            </div>
        </div>

        <br>

        <div class="row featurette align-items-center">
            <div class="col-md-2">
                <br>
                <img class="featurette-image img-responsive img-thumbnail"  src="publication/pbrnet/icon.jpg" alt="PBRNET" style="width:256px;" />
            </div>
            <div class="col-md-10">
                <h4 class="featurette-heading" data-toggle="tooltip" > PBR-Net: Imitating Physically Based Rendering using Deep Neural Network</h4>
                <p> P. Dai, Z. Li, <b>Y. Zhang</b>, S. Liu, B. Zeng</p>
                <p> IEEE Transactions on Image Processing, 16 Apr 2020, DOI: 10.1109/TIP.2020.2987169.</p>
                <p> 
                <!-- [<a href="Coming Soon">Paper</a>] -->
                <!-- [<a href="Coming Soon">Supplimentary</a>] -->
                [<a href="http://www.liushuaicheng.org/TIP/PBR-Net/PBR-Net.pdf">Paper</a>]
                </p>
            </div>
        </div>

        <br>

        <div class="row featurette align-items-center" id="publication_NPT">
            <div class="col-md-2">
                <img class="featurette-image img-responsive img-thumbnail"  src="publication/neuralposetransfer/icon.jpg" alt="NPT" style="width:256px;" />
            </div>
            <div class="col-md-10">
                <h4 class="featurette-heading" data-toggle="tooltip" > Neural Pose Transfer by Spatially Adaptive Instance Normalization</h4>
                <p> J. Wang, C. Wen, Y. Fu, H. Lin, T. Zou, X. Xue, <b>Y. Zhang</b></p>
                <p> Computer Vision and Pattern Recognition (CVPR 2020)</p>
                <p> 
                <!-- [<a href="Coming Soon">Paper</a>] -->
                <!-- [<a href="Coming Soon">Supplimentary</a>] -->
                [<a href="https://arxiv.org/pdf/2003.07254.pdf">Paper</a>]
                [<a href="https://jiashunwang.github.io/Neural-Pose-Transfer/">Project Webpage (Poster, Video)</a>]
                [<a href="https://github.com/jiashunwang/Neural-Pose-Transfer">Code and Data</a>]
                <!-- [<a href="https://www.dropbox.com/s/jgs0pijcseo7xtp/slides.pdf?dl=0">Oral Presentation</a>] -->
                <!-- [<a href="http://b1ueber2y.me/projects/DIST-Renderer/">Project Webpage</a>]
                [<a href="https://www.youtube.com/watch?v=A6-W55VZeK0&feature=emb_title">Video</a>] -->
                </p>
            </div>
        </div>

        <br>

        <div class="row featurette align-items-center">
            <div class="col-md-2">
                <br>
                <img class="featurette-image img-responsive img-thumbnail"  src="publication/deepcompression/icon.jpg" alt="NPT" style="width:256px;" />
            </div>
            <div class="col-md-10">
                <h4 class="featurette-heading" data-toggle="tooltip" > Deep Implicit Volume Compression</h4>
                <p> D. Tang, S. Singh, P. Chou, C. Haene, M. Dou, S. Fanello, J. Taylor, P. Davidson, O. Guleryuz, <b>Y. Zhang</b>, S. Izadi, A. Tagliasacchi, S. Bouaziz, C. Keskin </p>
                <p> Computer Vision and Pattern Recognition (CVPR 2020), Oral Presentation</p>
                <p> 
                [<a href="https://arxiv.org/abs/2005.08877">Paper</a>]
                [<a href="https://augmentedperception.github.io/deep_volume_compression/">Project Webpage</a>]
                [<a href="https://www.youtube.com/watch?v=2RMLcrSdNM4">Video</a>]
                </p>
            </div>
        </div>

        <br>

        <div class="row featurette align-items-center" id="publication_NPCR">
            <div class="col-md-2">
                <br>
                <img class="featurette-image img-responsive img-thumbnail"  src="publication/NPCR/icon.jpg" alt="NPCR" style="width:256px;" />
            </div>
            <div class="col-md-10">
                <h4 class="featurette-heading" data-toggle="tooltip" > Neural Point Cloud Rendering via Multi-Plane Projection</h4>
                <p> P. Dai<sup>*</sup>, <b>Y. Zhang<sup>*</sup></b>, Z. Li<sup>*</sup>, S. Liu, B. Zeng</p>
                <p> Computer Vision and Pattern Recognition (CVPR 2020)</p>
                <p> 
                <!-- [<a href="Coming Soon">Paper</a>] -->
                <!-- [<a href="Coming Soon">Supplimentary</a>] -->
                [<a href="https://arxiv.org/pdf/1912.04645.pdf">Paper</a>]
                [<a href="https://daipengwa.github.io/NeuralPointCloudRendering_ProjectPage/">Project Webpage</a>]
                [<a href="https://github.com/daipengwa/NeuralPointCloudRendering">Code and Data</a>]
                [<a href="https://drive.google.com/open?id=1V4DNSMfBF2LQ1ZIcaGo0auLgwpcbaP83">Poster</a>]
                [<a href="https://drive.google.com/open?id=1-_ZibCEyVGF80hleQOfKmqDR-ewpdQbc">Video</a>]
                </p>
            </div>
        </div>

        <br>

        <div class="row featurette align-items-center">
            <div class="col-md-2">
                <br>
                <img class="featurette-image img-responsive img-thumbnail"  src="publication/DIST/icon.png" alt="DIST" style="width:256px;" />
            </div>
            <div class="col-md-10">
                <h4 class="featurette-heading" data-toggle="tooltip" > DIST: Rendering Deep Implicit Signed Distance Function with Differentiable Sphere Tracing</h4>
                <p> S. Liu, <b>Y. Zhang</b>, S. Peng, B. Shi, M. Pollefeys, Z. Cui</p>
                <p> Computer Vision and Pattern Recognition (CVPR 2020)</p>
                <p> 
                <!-- [<a href="Coming Soon">Paper</a>] -->
                <!-- [<a href="Coming Soon">Supplimentary</a>] -->
                [<a href="https://arxiv.org/abs/1911.13225">Paper</a>]
                [<a href="http://b1ueber2y.me/projects/DIST-Renderer/dist-supp.pdf">Supplementary Material</a>]
                [<a href="https://github.com/B1ueber2y/DIST-Renderer">Code and Data</a>]
                <!-- [<a href="https://www.dropbox.com/s/jgs0pijcseo7xtp/slides.pdf?dl=0">Oral Presentation</a>] -->
                [<a href="http://b1ueber2y.me/projects/DIST-Renderer/">Project Webpage</a>]
                [<a href="https://www.youtube.com/watch?v=A6-W55VZeK0&feature=emb_title">Video</a>]
                [<a href="http://b1ueber2y.me/projects/DIST-Renderer/pdf/4986-poster.pdf">Poster</a>]
                [<a href="http://b1ueber2y.me/projects/DIST-Renderer/dist-slides.pdf">Slides</a>]
                </p>
            </div>
        </div>

        <br>

        <div class="row featurette align-items-center">
            <div class="col-md-2">
                <br>
                <img class="featurette-image img-responsive img-thumbnail"  src="publication/pixel2meshplus/icon.png" alt="Pixel2Mesh++" style="width:256px;" />
            </div>
            <div class="col-md-10">
                <h4 class="featurette-heading" data-toggle="tooltip" > Pixel2Mesh++: Multi-View 3D Mesh Generation via Deformation</h4>
                <p> C. Wen<sup>*</sup>, <b>Y. Zhang<sup>*</sup></b>, Z. Li<sup>*</sup>, Y. Fu </p>
                <p> International Conference on Computer Vision (ICCV 2019)</p>
                <p> 
                <!-- [<a href="Coming Soon">Paper</a>] -->
                <!-- [<a href="Coming Soon">Supplimentary</a>] -->
                [<a href="https://arxiv.org/abs/1908.01491">Paper</a>]
                [<a href="https://github.com/walsvid/Pixel2MeshPlusPlus">Code and Data</a>]
                <!-- [<a href="https://www.dropbox.com/s/jgs0pijcseo7xtp/slides.pdf?dl=0">Oral Presentation</a>] -->
                [<a href="https://walsvid.github.io/Pixel2MeshPlusPlus/">Project Webpage</a>]
                <!-- [<a href="publication/activestereo/bibtext.txt">BibTeX</a>] -->
                </p>
            </div>
        </div>

        <br>

        <div class="row featurette align-items-center">
            <div class="col-md-2">
                <br>
                <img class="featurette-image img-responsive img-thumbnail"  src="publication/deeplidar/icon.jpg" alt="DeepLidar" style="width:256px;" />
            </div>
            <div class="col-md-10">
                <h4 class="featurette-heading" data-toggle="tooltip" > DeepLiDAR: Deep Surface Normal Guided Depth Prediction for Outdoor Scene from Sparse LiDAR Data and Single Color Image </h4>
                <p> J. Qiu<sup>*</sup>, Z. Cui<sup>*</sup>, <b>Y. Zhang<sup>*</sup></b>, X. Zhang, S. Liu, B. Zeng, M. Pollefeys </p>
                <p> Computer Vision and Pattern Recognition (CVPR 2019)</p>
                <p> 
               	<!-- [<a href="Coming Soon">Paper</a>] -->
                <!-- [<a href="Coming Soon">Supplimentary</a>] -->
                [<a href="https://arxiv.org/pdf/1812.00488.pdf">Paper</a>]
                [<a href="https://github.com/JiaxiongQ/DeepLiDAR">Code and Data</a>]
                <!-- [<a href="https://www.dropbox.com/s/jgs0pijcseo7xtp/slides.pdf?dl=0">Oral Presentation</a>] -->
                <!-- [<a href="http://asn.cs.princeton.edu">Project Webpage</a>] -->
                <!-- [<a href="publication/activestereo/bibtext.txt">BibTeX</a>] -->
                </p>
            </div>
        </div>

        <br>

        <div class="row featurette align-items-center" id="publication_activestereo">
            <div class="col-md-2">
                <br>
                <img class="featurette-image img-responsive img-thumbnail"  src="publication/activestereo/icon.jpg" alt="ActiveStereoNet" style="width:256px;" />
            </div>
            <div class="col-md-10">
                <h4 class="featurette-heading" data-toggle="tooltip" > ActiveStereoNet: End-to-End Self-Supervised Learning for Active Stereo Systems </h4>
                <p> <b>Y. Zhang</b>, S. Khamis, C. Rhemann, J. Valentin, A. Kowdle, V. Tankovich, M. Schoenberg, S. Izadi, T. Funkhouser, S. Fanello </p>
                <p> European Conference on Computer Vision (ECCV 2018), Oral Presentation</p>
                <p> [<a href="https://www.dropbox.com/s/i75t6dliudm176d/paper.pdf?dl=0">Paper</a>]
                [<a href="https://www.dropbox.com/s/sm3a0fdd3kdnh8z/supp.pdf?dl=0">Supplimentary</a>]
                [<a href="https://arxiv.org/pdf/1807.06009.pdf">Arxiv</a>]
                [<a href="https://www.dropbox.com/s/jgs0pijcseo7xtp/slides.pdf?dl=0">Slides</a>]
                [<a href="https://www.youtube.com/watch?v=a4zXnWxt_rA">Oral Presentation</a>]
                [<a href="http://asn.cs.princeton.edu">Project Webpage</a>]
                <!-- [<a href="publication/activestereo/bibtext.txt">BibTeX</a>] -->
                </p>
            </div>
        </div>

        <br>

        <div class="row featurette" id="publication_pixel2mesh">
            <div class="col-md-2">
                <br>
                <img class="featurette-image img-responsive img-thumbnail"  src="publication/pixel2mesh/icon.jpg" alt="pixel2mesh" style="width:256px;" />
            </div>
            <div class="col-md-10">
                <h4 class="featurette-heading" data-toggle="tooltip" > Pixel2Mesh: Generating 3D Mesh Models from Single RGB Images </h4>
                <p> N. Wang<sup>*</sup>, <b>Y. Zhang<sup>*</sup></b>, Z. Li<sup>*</sup>, Y. Fu, W. Liu, Y. Jiang </p>
                <p> European Conference on Computer Vision (ECCV 2018)</p>
                <p> IEEE Transactions on Pattern Analysis and Machine Intelligence, 02 Apr 2020, DOI: 10.1109/TPAMI.2020.2984232.</p>
                <p> [<a href="https://www.dropbox.com/s/r03063omm6oybpp/paper.pdf?dl=0">Paper</a>]
                [<a href="https://arxiv.org/pdf/1804.01654.pdf">Arxiv</a>]
                <!-- [<a href="publication/activestereo/slides.pdf">Oral Presentation</a>] -->
                [<a href="https://github.com/nywang16/Pixel2Mesh">Code</a>]
                [<a href="http://bigvid.fudan.edu.cn/pixel2mesh">Project Webpage</a>]
                <!-- [<a href="publication/pixel2mesh/bibtext.txt">BibTeX</a>] -->
                </p>
            </div>
        </div>

        <br>

        <div class="row featurette">
            <div class="col-md-2">
                <br>
                <img class="featurette-image img-responsive img-thumbnail"  src="publication/deepcompletion/icon.jpg" alt="DeepCompletion" style="width:256px;" />
            </div>
            <div class="col-md-10">
                <h4 class="featurette-heading" data-toggle="tooltip" > Deep Depth Completion of a Single RGB-D Image </h4>
                <p> <b>Y. Zhang</b>, T. Funkhouser </p>
                <p> Computer Vision and Pattern Recognition (CVPR 2018)</p>
                <p> [<a href="https://www.dropbox.com/s/hnqqrsiw6e64tj0/paper.pdf?dl=0">Paper</a>]
                [<a href="https://www.dropbox.com/s/nuztkxzlstumo8i/supp.pdf?dl=0">Supplimentary</a>]
                [<a href="https://arxiv.org/pdf/1803.09326.pdf">Arxiv</a>]
                [<a href="https://www.dropbox.com/s/rqyk2nzfamznaqt/spotlight.pdf?dl=0">Spotlight Presentation</a>]
                [<a href="http://deepcompletion.cs.princeton.edu">Project Webpage</a>]
                [<a href="https://github.com/yindaz/DeepCompletionRelease">Code</a>]
                <!-- [<a href="publication/deepcompletion/bibtex.txt">BibTeX</a>] -->
                </p>
            </div>
        </div>

        <br>

        <div class="row featurette">
            <div class="col-md-2">
                <br>
                <img class="featurette-image img-responsive img-thumbnail"  src="publication/matterport3d/icon.png" alt="Matterport3d" style="width:256px;" />
            </div>
            <div class="col-md-10">
                <h4 class="featurette-heading" data-toggle="tooltip" > Matterport3D: Learning from RGB-D Data in Indoor Environments </h4>
                <p> A. Chang, A. Dai, T. Funkhouser, M. Halber, M. Niessner, M. Savva, S. Song, A. Zeng, <b>Y. Zhang</b> </p>
                <p> International Conference on 3D Vision (3DV 2017)</p>
                <p> [<a href="https://www.dropbox.com/s/5xwi7945tcyza1a/paper.pdf?dl=0">Paper</a>]
                [<a href="https://arxiv.org/pdf/1709.06158.pdf">Arxiv</a>]
                <!-- [<a href="publication/deepcompletion/supp.pdf">Supplimentary</a>] -->
                <!-- [<a href="publication/deepcompletion/3324.mp4">Spotlight Presentation</a>] -->
                [<a href="https://github.com/niessner/Matterport">Project Webpage</a>]
                <!-- [<a href="https://github.com/yindaz/DeepCompletionRelease">Code</a>] -->
                <!-- [<a href="publication/matterport3d/bibtex.txt">BibTeX</a>] -->
                </p>
            </div>
        </div>

        <br>

        <div class="row featurette">
            <div class="col-md-2">
                <br>
                <img class="featurette-image img-responsive img-thumbnail"  src="publication/pbrs/icon.jpg" alt="PBRS" style="width:256px;" />
            </div>
            <div class="col-md-10">
                <h4 class="featurette-heading" data-toggle="tooltip" > Physically-Based Rendering for Indoor Scene Understanding Using Convolutional Neural Networks </h4>
                <p> <b>Y. Zhang</b>, S. Song, E. Yumer, M. Savva, J. Lee, H. Jin, T. Funkhouser </p>
                <p> Computer Vision and Pattern Recognition (CVPR 2017)</p>
                <p> [<a href="https://www.dropbox.com/s/ox2pc71zc2r894d/paper.pdf?dl=0">Paper</a>]
                [<a href="https://www.dropbox.com/s/l7rnhyvulgmhzl0/supp.pdf?dl=0">Supplimentary</a>]
                [<a href="https://arxiv.org/pdf/1612.07429.pdf">Arxiv</a>]
                [<a href="http://pbrs.cs.princeton.edu">Project Webpage</a>]
                [<a href="https://github.com/yindaz/pbrs">Code</a>]
                <!-- [<a href="publication/pbrs/bibtex.txt">BibTeX</a>] -->
                </p>
            </div>
        </div>

        <br>

        <div class="row featurette">
            <div class="col-md-2">
                <br>
                <img class="featurette-image img-responsive img-thumbnail"  src="publication/deepcontext/icon.jpg" alt="DeepContext" style="width:256px;" />
            </div>
            <div class="col-md-10">
                <h4 class="featurette-heading" data-toggle="tooltip" > DeepContext: Context-Encoding Neural Pathways for 3D Holistic Scene Understanding </h4>
                <p> <b>Y. Zhang</b>, M. Bai, P. Kohli, S. Izadi, J. Xiao </p>
                <p> International Conference on Computer Vision (ICCV 2017) </p>
                <p> [<a href="https://www.dropbox.com/s/ylii5wzkhskkgou/paper.pdf?dl=0">Paper</a>]
                [<a href="https://www.dropbox.com/s/zs98td29nk10vbj/supp.pdf?dl=0">Supplimentary</a>]
                [<a href="https://arxiv.org/pdf/1603.04922.pdf">Arxiv</a>]
                [<a href="http://deepcontext.cs.princeton.edu/">Project Webpage</a>]
                [<a href="https://youtu.be/4kSdErN4W6Q">Video Youtube</a>]
                [<a href="https://www.dropbox.com/s/nbcr5qsfkc2ys3t/video.mp4?dl=0">Video Download</a>]
                <!-- [<a href="publication/deepcontext/bibtex.txt">BibTeX</a>] -->
                </p>
            </div>
        </div>

        <br>

        <div class="row featurette">
            <div class="col-md-2">
                <br>
                <img class="featurette-image img-responsive img-thumbnail"  src="publication/hand3d/icon.jpg" alt="Hand3D" style="width:256px;" />
            </div>
            <div class="col-md-10">
                <h4 class="featurette-heading" data-toggle="tooltip" >  Hand3D: Hand Pose Estimation using 3D Neural Network </h4>
                <p> X. Deng<sup>*</sup>, S. Yang<sup>*</sup>, <b>Y. Zhang<sup>*</sup></b>, P. Tan, L. Chang, H. Wang </p>
                <p>  arXiv:1704.02224 [cs.CV] (7 Apr 2017) </p>
                <p> [<a href="https://arxiv.org/pdf/1704.02224.pdf">Paper</a>]
                [<a href="http://www.idengxm.com/hand3d/index.html">Project Webpage</a>]
                <!-- [<a href="publications/bibtex.txt">BibTeX</a>] -->
                </p>
            </div>
        </div>

        <br>

        <div class="row featurette">
            <div class="col-md-2">
                <br>
                <img class="featurette-image img-responsive img-thumbnail"  src="publication/jointhand/icon.jpg" alt="jointhand" style="width:256px;" />
            </div>
            <div class="col-md-10">
                <h4 class="featurette-heading" data-toggle="tooltip" >  Joint Hand Detection and Rotation Estimation Using CNN </h4>
                <p> X. Deng, <b>Y. Zhang</b>, S. Yang, P. Tan, L. Chang, Y. Yuan, H. Wang </p>
                <p> IEEE Transactions on Image Processing, 04 Dec 2017, DOI: 10.1109/TIP.2017.2779600.</p>
                <p> [<a href="https://www.dropbox.com/s/iecjrvfnfpi94fu/paper.pdf?dl=0">Paper</a>]
                [<a href="http://www.idengxm.com/handdetection/index.html">Project Webpage</a>]
                <!-- [<a href="publications/bibtex.txt">BibTeX</a>] -->
                </p>
            </div>
        </div>

        <br>

        <div class="row featurette">
            <div class="col-md-2">
                <br>
                <img class="featurette-image img-responsive img-thumbnail"  src="publication/lsun/icon.jpg" alt="LSUN" style="width:256px;" />
            </div>
            <div class="col-md-10">
                <h4 class="featurette-heading" data-toggle="tooltip" > LSUN: Construction of a Large-scale Image Dataset using Deep Learning with Humans in the Loop </h4>
                <p> F. Yu, A. Seff, <b>Y. Zhang</b>, S. Song, T. Funkhouser, J. Xiao </p>
                <p> arXiv:1506.03365 [cs.CV] 10 Jun 2015 </p>
                <p> [<a href="https://arxiv.org/pdf/1506.03365">Paper</a>]
                <!-- [<a href="publication/panocontext/supp.pdf">Supplimentary</a>] -->
                <!-- [<a href="publication/deepcompletion/3324.mp4">Spotlight Presentation</a>] -->
                [<a href="http://lsun.cs.princeton.edu/2017/">Project Webpage</a>]
                <!-- [<a href="https://youtu.be/4kSdErN4W6Q">Video</a>] -->
                <!-- [<a href="publication/lsun/bibtex.txt">BibTeX</a>] -->
                </p>
            </div>
        </div>

        <br>

        <div class="row featurette">
            <div class="col-md-2">
                <br>
                <img class="featurette-image img-responsive img-thumbnail"  src="publication/turkergaze/icon.jpg" alt="Turkergaze" style="width:256px;" />
            </div>
            <div class="col-md-10">
                <h4 class="featurette-heading" data-toggle="tooltip" > TurkerGaze: Crowdsourcing Saliency with Webcam based Eye Tracking </h4>
                <p> P. Xu, K. A. Ehinger, <b>Y. Zhang</b>, A. Finkelstein, S. R. Kulkarni, J. Xiao </p>
                <p> arXiv:1504.06755 [cs.CV] 25 Apr 2015 </p>
                <p> [<a href="https://www.dropbox.com/s/9mi2n3ql9fir53j/paper.pdf?dl=0">Paper</a>]
                [<a href="https://www.dropbox.com/s/pjn3h9i3h7qdq36/supp.pdf?dl=0">Supplimentary</a>]
                [<a href="https://youtu.be/jMY-ALt0xh0">Video Youtube</a>]
                [<a href="https://www.dropbox.com/s/4lzqycyt6slsqgp/TurkerGaze_with_audio.mp4?dl=0">Video Download</a>]
                [<a href="http://vision.princeton.edu/projects/2014/iSUN/">Project Webpage</a>]
                <!-- [<a href="https://youtu.be/4kSdErN4W6Q">Video</a>] -->
                <!-- [<a href="publication/turkergaze/bibtex.txt">BibTeX</a>] -->
                </p>
            </div>
        </div>

        <br>

        <div class="row featurette">
            <div class="col-md-2">
                <br>
                <img class="featurette-image img-responsive img-thumbnail"  src="publication/panocontext/icon.jpg" alt="PanoContext" style="width:256px;" />
            </div>
            <div class="col-md-10">
                <h4 class="featurette-heading" data-toggle="tooltip" > PanoContext: A Whole-room 3D Context Model for Panoramic Scene Understanding </h4>
                <p> <b>Y. Zhang</b>, S. Song, P. Tan, and J. Xiao </p>
                <p> European Conference on Computer Vision (ECCV 2014), Oral Presentation </p>
                <p> [<a href="https://www.dropbox.com/s/f5j33ctbmcogzpa/paper.pdf?dl=0">Paper</a>]
                [<a href="https://www.dropbox.com/s/avbydn89h92rsz7/supp_compress.pdf?dl=0">Supplimentary</a>]
                [<a href="https://www.dropbox.com/s/lyj277ql2fwui6d/slides.pdf?dl=0">Oral Presentation</a>]
                [<a href="http://videolectures.net/eccv2014_zhang_panoramic_scene/">Conference Talk</a>]
                [<a href="https://youtu.be/8I-v6gQXfD8">Detailed Video Youtube</a>]
                [<a href="https://www.dropbox.com/s/khyae5roghbilnt/ECCV_longvideo.mp4?dl=0">Detailed Video Download (8min)</a>]
                [<a href="https://www.dropbox.com/s/h50sgub0my0axgi/ECCV_spotlight.mp4?dl=0">Short Video Download (1min)</a>]
                [<a href="http://panocontext.cs.princeton.edu/">Project Webpage</a>]
                <!-- [<a href="https://youtu.be/4kSdErN4W6Q">Video</a>] -->
                <!-- [<a href="publication/panocontext/bibtex.txt">BibTeX</a>] -->
                </p>
            </div>
        </div>

        <br>

        <div class="row featurette">
            <div class="col-md-2">
                <br>
                <img class="featurette-image img-responsive img-thumbnail"  src="publication/framebreak/icon.jpg" alt="FrameBreak" style="width:256px;" />
            </div>
            <div class="col-md-10">
                <h4 class="featurette-heading" data-toggle="tooltip" > FrameBreak: Dramatic Image Extrapolation by Guided Shift-Maps </h4>
                <p> <b>Y. Zhang</b>, J. Xiao, J. Hays, P. Tan </p>
                <p> Computer Vision and Pattern Recognition (CVPR 2013) </p>
                <p> [<a href="https://www.dropbox.com/s/d80f2mhry47xdi4/paper.pdf?dl=0">Paper</a>]
                [<a href="https://www.dropbox.com/s/ka05faw5rnxo6az/supp.pdf?dl=0">Supplimentary</a>]
                <!-- [<a href="publication/deepcompletion/3324.mp4">Spotlight Presentation</a>] -->
                [<a href="https://vision.princeton.edu/projects/2013/framebreak/">Project Webpage</a>]
                <!-- [<a href="https://youtu.be/4kSdErN4W6Q">Video</a>] -->
                <!-- [<a href="publication/framebreak/bibtex.txt">BibTeX</a>] -->
                </p>
            </div>
        </div>

        <br>

        <!-- <div class="row featurette">
            <div class="col-md-2">
                <br>
                <img class="featurette-image img-responsive img-thumbnail"  src="publication/icon.png" alt="Ph.D. Thesis" style="width:256px;" />
            </div>
            <div class="col-md-10">
                <h4 class="featurette-heading" data-toggle="tooltip" > From Pixels to Scenes: Recovering 3D Geometry and Semantics for Indoor Environments </h4>
                <p> Yinda Zhang </p>
                <p> <i>Ph.D. Thesis</i>. Princeton University, 2018</p>
                <p> [<a href="publication/Yinda_Zhang_Thesis.pdf">PDF</a>]
                [<a href="publications/fpo-compressed.pdf">Slides</a>]
                [<a href="publications/bibtex.txt">BibTeX</a>]
                </p>
            </div>
        </div> -->

        <div id="experience"></div>
        <br>
        <div class="page-header">
            <h2>Experiences</h2>
        </div>

        <div class="media">
            <div class="media-left">
              <a href="https://vr.google.com/daydream/">
                <img class="media-object" style="width:64px;" src="./img/google-1.jpg" alt="GOOGLE">
              </a>
            </div>
            <div class="media-body">
              <h4 class="media-heading">Google, Mountain View</h4>
              <p>Research Scientist<br>12/2018--Present</p>
            </div>
        </div>

        <div class="media">
            <div class="media-left">
              <a href="http://www.cs.princeton.edu/">
                <img class="media-object" style="width:64px;" src="./img/princeton-1.jpg" alt="Princeton">
              </a>
            </div>
            <div class="media-body">
              <h4 class="media-heading">Princeton University, <a href="http://3dvision.princeton.edu">Vision and Robotics Group</a></h4>
              <p>Ph.D. in <a href="http://www.cs.princeton.edu/">Department of Computer Science</a><br>09/2014--11/2018</p>
            </div>
        </div>

        <div class="media">
            <div class="media-left">
              <a href="https://vr.google.com/daydream/">
                <img class="media-object" style="width:64px;" src="./img/google-1.jpg" alt="GOOGLE">
              </a>
            </div>
            <div class="media-body">
              <h4 class="media-heading">Google (through AutoRoboto Inc.), Mountain View</h4>
              <p>Research Intern<br>09/2017--10/2018</p>
            </div>
        </div>

        <div class="media">
            <div class="media-left">
              <a href="https://matterport.com/">
                <img class="media-object" style="width:64px;" src="./img/matterport-1.jpg" alt="MATTERPORT">
              </a>
            </div>
            <div class="media-body">
              <h4 class="media-heading">Matterport Inc., Sunnyvale</h4>
              <p>Research Intern<br>06/2017--08/2017</p>
            </div>
        </div>

        <div class="media">
            <div class="media-left">
              <a href="https://research.adobe.com/">
                <img class="media-object" style="width:64px;" src="./img/adobe-1.jpg" alt="ADOBE">
              </a>
            </div>
            <div class="media-body">
              <h4 class="media-heading">Adobe Research, San Jose</h4>
              <p>Research Intern<br>06/2016--08/2016</p>
            </div>
        </div>

        <div class="media">
            <div class="media-left">
              <a href="https://www.microsoft.com/en-us/research/">
                <img class="media-object" style="width:64px;" src="./img/microsoft-1.jpg" alt="MSR">
              </a>
            </div>
            <div class="media-body">
              <h4 class="media-heading">Microsoft Research, Redmond</h4>
              <p>Research Intern<br>07/2015--08/2015</p>
            </div>
        </div>

        <div class="media">
            <div class="media-left">
              <a href="http://nus.edu.sg/">
                <img class="media-object" style="width:64px;" src="./img/nus-1.jpg" alt="NUS">
              </a>
            </div>
            <div class="media-body">
              <h4 class="media-heading">National University of Singapore, Singapore</h4>
              <p>M.Eng. in <a href="http://ece.nus.edu.sg/drupal/">Department of Electrical and Computer Engineering</a><br>01/2010--01/2013</p>
            </div>
        </div>

        <div class="media">
            <div class="media-left">
              <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/">
                <img class="media-object" style="width:64px;" src="./img/microsoft-1.jpg" alt="MSRA">
              </a>
            </div>
            <div class="media-body">
              <h4 class="media-heading">Microsoft Research Asia, Beijing, <a href="https://www.microsoft.com/en-us/research/research-area/computer-vision/">Vision Computing Group</a></h4>
              <p>Research Intern<br>05/2010--08/2011</p>
            </div>
        </div>

        <div class="media">
            <div class="media-left">
              <a href="http://www.tsinghua.edu.cn">
                <img class="media-object" style="width:64px;" src="./img/tsinghua-1.jpg" alt="Tsinghua">
              </a>
            </div>
            <div class="media-body">
              <h4 class="media-heading">Tsinghua University, Beijing</h4>
              <p>B.Eng. in <a href="https://www.tsinghua.edu.cn/publish/auen/">Department of Automation</a><br>08/2005--08/2009</p>
            </div>
        </div>
        
        <div id="service"></div>
        <br>
        <div class="page-header">
            <h2>Services and Awards</h2>
        </div>

        <h4>Invited Talk:</h4>
        <ul>

        <li><a href="https://augmentedperception.github.io/cvpr19/">Towards Relightable Volumetric Performance Capture of Humans (CVPR 2019)</a>
        <li><a href="http://games-cn.org/">GAMES: Graphics And Mixed Environment Seminar (2019.1)</a>. [<a href="https://v.qq.com/x/page/r0843mzadvi.html">Presentation (Chinese)</a>]
        <li><a href="https://augmentedperception.github.io/eccv18/">UltraFast 3D Sensing, Reconstruction and Understanding of People, Objects and Environments (ECCV 2018)</a></li>
        <li><a href="https://augmentedperception.github.io/cvpr18/">UltraFast 3D Sensing, Reconstruction and Understanding of People, Objects and Environments (CVPR 2018)</a></li>
        
        </ul>

        <br>

        <h4>Organizer of Workshops & Tutorial:</h4>
        <ul>
        <li><a href="http://lsun.cs.princeton.edu">Large-scale Scene Understanding Challenge Workshop (CVPR 2016)</a></li>
        <li><a href="http://lsun.cs.princeton.edu">Large-scale Scene Understanding Challenge Workshop (CVPR 2015)</a></li>
        <li>Tutorial on 3D Deep Learning with Marvin (CVPR 2016)</li>
        </ul>

    <!--     <br>
        
        <h4>Academic Dataset:</h4>
        <ul>
        <li><a href="https://niessner.github.io/Matterport/">Matterport3D: </a></li>
        <li><a href="http://lsun.cs.princeton.edu">Depth Completion Dataset</a></li>
        <li><a href="http://lsun.cs.princeton.edu">LSUN</a></li>
        <li><a href="http://lsun.cs.princeton.edu">iSUN</a></li>
        </ul> -->

        <br>

        <h4>Reviewer of Conferences:</h4>
        <p>CVPR, ECCV, ICCV, SIGGRAPH, NIPS, AAAI, BMVC, 3DV, ACCV, ICPR, ICRA</p>

        <br>
        <h4>Reviewer of Journals:</h4>
        <p>PAMI, IJCV, TOG, MVAP, TIP, NEUCOM</p>
      
        <br>
        <h4>Awards:</h4>
          <ul>
            <li><a href="http://www.siebelscholars.com/">Siebel Scholars</a>, Class of 2019</li>
            <li>Outstanding Reviewer in <a href="http://cvpr2018.thecvf.com/program/reviewer_acknowledgements">CVPR2018</a></li>
            <li>Silver Medal for National Olympic Competition of Physics, China, 2004</li>
          </ul>

        <br>
        <h4>Teaching:</h4>
        <ul>
        <li>Preceptor and Teaching Assistant: <a href="https://www.cs.princeton.edu/courses/archive/spring16/cos435/">Princeton COS435 Information Retrival</a>, 2016 Spring</li>
        <li>Preceptor and Teaching Assistant: <a href="http://vision.princeton.edu/courses/COS429/2015fa/">Princeton COS429 Computer Vision</a>, 2015 Fall</li>
        </ul>

        <br>
        <h4>Previously Monitored Students:</h4>
        <ul>
            <li><a href="http://b1ueber2y.me/">Shaohui Liu</a>, University of Washington/Tsinghua University.</li>
            <li>Jiashun Wang, University of California San Diego/Fudan University.</li>
            <li><a href="https://walsvid.github.io/">Chao Wen</a>, Fudan University.</li>
            <li><a href="https://www.linkedin.com/in/nywang16/">Nanyang Wang</a>, Alibaba.</li>
            <li>Peng Dai, University of Hong Kong.</li>
            <li><a href="https://jiaxiongq.github.io/">Jiaxiong Qiu</a>, University of Electronic Science and Technology of China.</li>
            <li>Ye Yuan, Face++.</li>
        </ul>

        <!-- <div class="page-header" id="talk">
            <h2>Talks</h2>
        </div> -->

        <div id="contact"></div>
        <br>
        <div class="page-header">
            <h2>Contacts</h2>
        </div>

        <table>
            <tr><td>Email:&nbsp;&nbsp;</td><td>yinda<span class="hiddenemail">nospam</span>z (at) gmail (dot) com</td></tr>
            <tr><td>&nbsp;</td><td></td></tr>
            <tr><td>Address:&nbsp;&nbsp;</td><td>1600 Amphitheatre Pkwy,</td></tr>
            <!-- <tr><td></td><td>35 Olden Street,</td></tr> -->
            <tr><td></td><td>Mountain View, CA, US, 94043</td></tr>
            <tr><td>&nbsp;</td><td></td></tr>

          </table>


        <hr>
        <footer>
            <p>&copy; Yinda Zhang, 2020</p>
        </footer>

    <div>


    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://code.jquery.com/jquery-1.10.2.min.js"></script>
    <script src="js/bootstrap.min.js"></script>
    <script>
        var prevScrollpos = window.pageYOffset;
        window.onscroll = function() {
        var currentScrollPos = window.pageYOffset;
          if (prevScrollpos > currentScrollPos) {
            document.getElementById("navbar").style.top = "0";
          } else {
            document.getElementById("navbar").style.top = "-50px";
          }
          prevScrollpos = currentScrollPos;
        }
    </script>
  </body>
</html>

